研究目标
本课题研究目的是根据以上背景，利用基于Python技术的开源库，探索性的实现一个自定义的拓展能力强的网络爬虫原型程序。
1.基于Scrapy框架，实现多线程抓取
2.选择合适的数据库进行数据存取
3.完成以上目标后，探索性重构为分布式爬虫。


研究意义：
1.  深入学习Python和Scrapy开源框架，自己动手实现一个有良好拓展性的网络爬虫原型，将对我们学习新技术和拓宽眼界有着积极的作用。

2.  虽然实现的只是一个原型程序，但是探索简单易模改易拓展的思路是非常正确的。不同领域、不同背景的用户往往具有不同的检索目的和需求，通用搜索引擎所返回的结果包含大量用户不关心的网页。为了解决这个问题，一个灵活的爬虫有着无可替代的重要意义。

3.  可以给 Python 这门编程语言在校园的推广起到一定的推进作用。为以后想使用 Python 技术做搜索引擎的同学提供一定的参考。

研究中将会遇到的关键问题

1.突破目标网页对爬虫的限制，如拒绝访问、强制登出、封锁IP等。破解网页的限制将是爬虫是否能高效运作的关键。

2.解决URL重复问题。在高速运行的爬虫工作过程中，如何鉴别即将爬取的网页是否已经爬取过极大影响了运行效率和资源的利用程度。在单机试验中，我们更需要加强对资源的掌控。

3.多线程并发实现。根据爬取目标的网页设计，如何设计更加高效利用CPU能力，怎样设计多线程的并发代码也需要学习解决。

4. 探索分布式爬虫实现的可能性。利用多台计算机组成小规模的分布式网络，协调处理一个问题，将对爬虫的性能有极大的提升，以及对我们了解网络组成和更高层次的算法有极大的帮助。
