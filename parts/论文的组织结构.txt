本论文的组织结构如下，一共为 六章，从第2章开始为论文正文部分，安排如下：

第二章为当前流行的爬虫技术的工作原理及相关技术介绍。首先介绍了当前爬虫技术的分类组织以及不同类型爬虫的工作重点以及其他区别。接着介绍主流爬虫所采用的关键算法，讲解算法的原理，分析算法的效率，介绍不同算法的优劣势。比如宽度优先搜索和广度优先算法等。然后论述了其他在爬虫工作过程中起重要作用的因素，如网页自身限制或者存取方式的差异等。由此引出当前很多网页对爬虫程序的访问限制，重点介绍Robot协议。接着是Cookies在当前前端技术中的广泛运用。并详细分析Cookies的原理和作用。

第三章为开源框架Scrapy在Python爬虫开发中的应用。首先对本文中使用的Scrapy爬虫框架进行分析，详细介绍如何使用，并分析针对URL去重问题中，Scrapy中便利的解决方式。
然后对数据存取的方式进行介绍，理性分析了不同类型数据库的优劣，详细介绍以MongoDB为代表的NoSQL数据库在爬虫技术中独特的优势。

第四章为聚焦原型爬虫系统的实现和展示。作者以流行的社交网站“新浪微博”为目标，实现了可以爬取用户信息、微博内容等结果的自定义爬虫。结合代码介绍了程序的详细实现及上文提到的关键问题的解决方法。如抓取方法，Cooikes处理，数据库模块，并结合Flask尝试将数据库中保存的抓取结果组织展示到网页中去。

第五章为探索分布式爬虫的实现和测试，介绍了分布式技术的原理和根据。不强求实现健壮的立即可用的分布式爬虫，而是在探索的过程中，获得对爬虫技术的进一步认识。以及对爬虫未来的发展提出展望。

第六部分为结论，对本文所做的工作进行了总结，陈述了在这次设计中取得的收获，并且在最后指出了本文的研究贡献。


