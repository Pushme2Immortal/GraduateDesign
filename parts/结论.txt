本文基于Python和Scrapy等开源技术，实现了一个易定制易拓展的聚焦爬虫。此网络爬虫以”新浪微博“的用户为目标，抓取围绕用户的信息。事实证明，利用Scrapy进行爬虫开发将极大地提高效率，带来了很大的便利。同时还兼顾了爬虫的性能，在单机测试下可以达到1300万条/天的爬取速度，成功达到了预期标准。
 
本文研究实现的基于Python 技术的网络爬虫对 Python 语言在校园的推广也
起到了一定的积极作用。Python 语言不光简单易用，功能强大，并且有着强大的开
源社区的支持，在实践过程中能体会到巨大的乐趣。希望Python课程能够在计算机学院中普遍展开。
 
本文的研究工作具有一定的科学研究价值和实际应用价值。然而，本文的原型
系统仍有许多待完善的地方。我认为，应该在以下几个方面进行改进：
1）单机性能不够强大，可以考虑引入Redis开源框架，实现爬虫的分布化，多机合作将极大提高爬虫的性能。
2）开发出基于此爬虫的搜索引擎。用户可以选择关键词来搜索，实现前端的交互。
3）可以拓展到其他网站中去，如对文献内容的搜索，将非常具有公益性。

通过本次研究，我们可以发现，爬虫技术已经深入到我们身边的每一处。学会爬虫开发，让我们对搜索引擎有了更好的理解，通过搜索引擎看世界的眼光也得到了提升。这也启发我们，看起来高端先进的技术其实都有着友好的基础，不要畏惧困难，从简单入门，我们也将可以接触并开发前沿技术，推动世界发展。在学习爬虫的过程中，我不仅仅学习到Python方面的知识。爬虫是一个系统工程，从前端到数据库后台，在设计过程中都需要用心去学习。

