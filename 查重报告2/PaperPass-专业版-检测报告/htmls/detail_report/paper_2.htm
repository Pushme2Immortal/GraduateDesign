<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>PaperPass 最权威论文抄袭检测系统</title>
<style type="text/css">
<!--
user_icon {
color: #FFFFFF;
}
html
{
overflow-x:hidden;
overflow-y:auto;
}
body,td,th {
font-family: "微软雅黑";
font-size: 12px;
}
h1,h2,h3,h4,h5,h6 {
font-family: "宋体";
}
p{
margin-bottom:10px;
}
demo_padding {
line-height: 30px;
}
.zhengwen {
padding-right: 15px;
padding-left: 5px;
padding-bottom:100px;
font-size: 13px;
line-height: 20px;
color: #666666;
}
.zhengwencenter {
padding-right: 15px;
padding-left: 0px;
margin-bottom:10px;
font-size: 13px;
line-height: 20px;
color: #666666;
text-align:center
}
.neikuang {
background-color: #EBEBEB;
border: 1px solid #999999;
padding-right: 10px;
padding-left: 10px;
margin-top:10px;
margin-left:25px;
width:300px;
}
.shubu{
height: 20px;
width: 20px;
margin-left:25px;
background-color: #FFFFFF;
border: 1px solid #999999;
text-align: center;
vertical-align: middle;
display: block;
color: #666666;
}
a.red:link {color:#FF0000}
a.red:visited {color:#FF0000}
a.red:hover {color:#000000}
a.red:active {color:#000000}

a.orange:link {color:#FF6600}
a.orange:visited {color:#FF6600}
a.orange:hover {color:#000000}
a.orange:active {color:#000000}

a.dark:link {color:#666666}
a.dark:visited {color:#666666}
a.dark:hover {color:#000000}
a.dark:active {color:#000000}

a.pagelink:hover {color:#000000}
a.pagelink:active {color:#000000}

.green{color:#008000}
.gray{color:#666666}
.red{color:#FF0000}
.orange{color:#FF6600}
a{TEXT-DECORATION:none}

-->
</style>
</head>
<body>


<div class="zhengwen">
<div>
<span style="margin-left:25px"></span>
[
<a class="pagelink" href="paper_1.htm">首页</a>
<a class="pagelink" href="paper_1.htm">上一页</a>
<a class="pagelink" href="paper_3.htm">下一页</a>
<a class="pagelink" href="paper_6.htm">尾页</a>
页码：2/6页
]
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">41</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图2-1 通用爬虫框架流程</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">42</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/101.htm' target='right' class='red' >然后将其和网页相对路径名称交给网页下载器，网页下载器负责页面内容的下载。</a><a href='../sentence_detail/102.htm' target='right' class='red' >对于下载到本地的网页，一方面将其存储到页面库中，等待</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">43</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>建立索引等后续处理;</span><a href='../sentence_detail/104.htm' target='right' class='red' >另一方面将下载网页的URL放入已抓取URL队列中，这个队列记载了爬虫系统已经下载过的网页URL，以避免网页的重复抓取。</a><a href='../sentence_detail/105.htm' target='right' class='red' >对于刚下载的网页，从中抽取出所包含的所有链接信息，并在已抓取 URL队列中检查，如果发现链接还没有被抓取过，</a><a href='../sentence_detail/106.htm' target='right' class='red' >则将这个 URL放入待抓取 URL队列末尾，在之后的抓取调度中会下载这个 URL对应的网页。</a><a href='../sentence_detail/107.htm' target='right' class='red' >如此这般，形成循环，直到待抓取URL队列为审，这代表着爬虫系统已将能够抓取的网页尽数抓完，此时完成了一轮完整的抓取过程。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">44</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/108.htm' target='right' class='orange' >上述是一个通用爬虫的整体流程，如果从更加宏观的角度考虑，处于动态抓取过程中的爬虫和互联网所有网页之间的关系，</a><a href='../sentence_detail/109.htm' target='right' class='orange' >可以大致像如图2-2所示那样，将互联网页面划分为5个部分：</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">45</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图2-2 从爬虫角度看的网页分类</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">46</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1.已下载网页集合：</span><a href='../sentence_detail/112.htm' target='right' class='red' >爬虫已经从互联网下载到本地进行索引的网页集合。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">47</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.已过期网页集合：</span><a href='../sentence_detail/114.htm' target='right' class='red' >由于网页数最巨大，爬虫完整抓取一轮需要较长时间，在抓取过程中，很多已经下载的网页可能过期。</a><a href='../sentence_detail/115.htm' target='right' class='red' >之所以如此，是因为互联网网页处于不断的动态变化过程中，所以易产生本地网页内容和真实互联网网页不一致的情况。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">48</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.待下载网页集合：</span><a href='../sentence_detail/117.htm' target='right' class='red' >即处于上图中待抓取URL队列中的网页，这些网页即将被爬虫下载。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">49</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>4.可知网页集合：</span><a href='../sentence_detail/119.htm' target='right' class='red' >这些网页还没有被爬虫下载，也没有出现在待抓取 URL队列中，不过通过已经抓取的网页或者在待抓取 URL队列中的网页，</a><a href='../sentence_detail/120.htm' target='right' class='red' >总足能够通过链接关系发现它们，稍晚时候会被爬虫抓取并索引。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">50</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>5.不可知网页集合：</span><a href='../sentence_detail/122.htm' target='right' class='red' >有些网页对于爬虫来说是无法抓取到的，这部分网页构成了不可知网页集合。</a><a href='../sentence_detail/123.htm' target='right' class='red' >事实上，这部分网页所占的比例很高。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">51</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.2 常见的抓取策略</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">52</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>自从1994 年4 月世界上第一个Web 检索工具Web Crawler 问世以来， 目前较流行的搜索引擎已有Google、Yahoo、AltaVista、Infoseek、InfoMarket等。</span><a href='../sentence_detail/126.htm' target='right' class='red' >出于商业机密的考虑， 目前各个搜索引擎使用的Crawler 系统的技术内幕一般都不公开，现有的文献也仅限于概要性介绍。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">53</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/127.htm' target='right' class='red' >随着 Web信息资源呈指数级增长及 Web信息资源动态变化，传统的搜索引擎提供的信息检索服务已不能满足人们日益增长的对个性化服务的需要，</a><span class='green'>它们正面临着巨大的挑战。</span><a href='../sentence_detail/129.htm' target='right' class='red' >以何种策略访问Web提高搜索效率成为近年来专业搜索引擎网络爬虫研究的主要问题之一。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">54</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.2.1 宽度或深度优先搜索策略</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">55</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/131.htm' target='right' class='red' >搜索引擎所用的第一代网络爬虫主要是基于传统的图算法，如宽度优先或深度优先算法来索引整个 Web，</a><a href='../sentence_detail/132.htm' target='right' class='red' >一个核心的 URL集被用来作为一个种子集合，这种算法递归的跟踪超链接到其它页面，</a><a href='../sentence_detail/133.htm' target='right' class='red' >而通常不管页面的内容，因为最终的目标是这种跟踪能覆盖整个 Web。</a><a href='../sentence_detail/134.htm' target='right' class='red' >这种策略通常用在通用搜索引擎中，因为通用搜索引擎获得的网页越多越好，没有特定的要求。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">56</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1.宽度优先搜索算法</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">57</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/136.htm' target='right' class='red' >是最简便的图的搜索算法之一，这一算法也是很多重要的图的算法的原型。</a><a href='../sentence_detail/137.htm' target='right' class='red' >Dijktra 单源最短路径算法和Prim 最小生成树算法都采用了和宽度优先搜索类似的思想。</a><a href='../sentence_detail/138.htm' target='right' class='red' >宽度优先搜索算法是沿着树的宽度遍历树的节点，如果发现目标则算法中止。</a><a href='../sentence_detail/139.htm' target='right' class='red' >该算法的设计和实现相对简单属于盲目搜索。</a><a href='../sentence_detail/140.htm' target='right' class='red' >在目前为覆盖尽可能多的网页，一般使用宽度优先搜索方法。</a><a href='../sentence_detail/141.htm' target='right' class='red' >也有很多研究将宽度优先搜索策略应用于聚焦爬虫中。</a><a href='../sentence_detail/142.htm' target='right' class='red' >其基本思想是认为与初始URL 在一定链接距离内的网页具有主题相关性的概率很大。</a><a href='../sentence_detail/143.htm' target='right' class='red' >另外一种方法是将宽度优先搜索与网页过滤技术结合使用，先用广度优先策略抓取网页，再将其中无关的网页过滤掉。</a><a href='../sentence_detail/144.htm' target='right' class='red' >这些方法的缺点在于，随着抓取网页的增多大量的无关网页将被下载并过滤，算法的效率将变低。</a><span class='green'>基本原理如图2-3所示：</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">58</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图2-3 广度优先搜索</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">59</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.深度优先搜索</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">60</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/148.htm' target='right' class='red' >深度优先搜索所遵循的搜索策略是尽可能“深”地搜索图。</a><a href='../sentence_detail/149.htm' target='right' class='red' >在深度优先搜索中，对于最新发现的顶点，如果它还有以此为起点而未探测到的边 就沿此边继续搜索下去。</a><span class='green'>如图2-4所示：</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">61</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图2-4 深度优先搜索</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">62</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.2.2 聚焦搜索策略</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">63</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/153.htm' target='right' class='red' >基于第一代网络爬虫的搜索引擎抓取的网页一般少于1000000个网页， 极少重新搜集网页并去刷新索引。</a><a href='../sentence_detail/154.htm' target='right' class='red' >而且其检索速度非常慢，一般都要等待10s甚至更长的时间。</a><a href='../sentence_detail/155.htm' target='right' class='red' >随着网页页信息的指数级增长及动态变化，这些通用搜索引擎的局限性越来越大，随着科学技术的发展， 定向抓取相关网页资源的聚焦爬虫便应运而生。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">64</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/156.htm' target='right' class='red' >聚焦爬虫的爬行策略只挑出某一个特定主题的页面，根据“最好优先原则”进行访问，快速、有效地获得更多的与主题相关的页面，</a><a href='../sentence_detail/157.htm' target='right' class='red' >主要通过内容和 Web的链接结构来指导进一步的页面抓取。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">65</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/158.htm' target='right' class='red' >聚焦爬虫会给它所下载下来的页面分配一个评价分，然后根据得分排序。</a><span class='green'>最后插入到一个队列中。</span><a href='../sentence_detail/160.htm' target='right' class='red' >最好的下一个搜索将通过对弹出队列中的第一个页面进行分析而执行，这种策略保证爬虫能优先跟踪那些最有可能链接到目标页面的页面。</a><a href='../sentence_detail/161.htm' target='right' class='red' >决定网络爬虫搜索策略的关键是如何评价链接价值，即链接价值的计算方法，不同的价值评价方法计算出的链接的价值不同，</a><a href='../sentence_detail/162.htm' target='right' class='red' >表现出的链接的“重要程度”也不同，从而决定了不同的搜索策略。</a><a href='../sentence_detail/163.htm' target='right' class='red' >这种策略通常运用在专业搜索引擎中，因为这种搜索引擎只关心某一特定主题的页面。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">66</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.3 Cookie的介绍和作用</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">67</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.3.1 什么是Cookie</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">68</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/166.htm' target='right' class='red' >Cookie 是一小段文本信息，伴随着用户请求和页面在 Web 服务器和浏览器之间传递。</a><a href='../sentence_detail/167.htm' target='right' class='red' >用户每次访问站点时，Web 应用程序都可以读取 Cookie 包含的信息。</a><a href='../sentence_detail/168.htm' target='right' class='red' >因为HTTP协议是无状态的，即服务器不知道用户上一次做了什么，这严重阻碍了交互式Web应用程序的实现。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">69</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/169.htm' target='right' class='orange' >Cookie一个典型的应用场景是当登录一个网站时，站点可能需要我们输入用户名和密码，并往往提供”下次自动登录“勾选功能。</a><span class='green'>如果我们选择勾选，那么在这次登录过程中，服务器将我们的用户名和密码的加密密文发送到此页面的Cookie中，并保存至本地硬盘。</span><a href='../sentence_detail/171.htm' target='right' class='orange' >在之后的登录中，进入到登录界面，浏览器将自动从本地调用Cookie至服务器端进行验证，实现了自动登录。</a><span class='green'>所以Cookie中往往保存了站点的用户名和加密密码。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">70</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.3.2 Cookie的缺陷</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">71</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/174.htm' target='right' class='orange' >1. 每个Http请求中都包含当前页面的Cookie，增加了网络传输的流量</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">72</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2．Cookie在http请求中是通过明文方式进行传递，所以不具备良好的安全性，易追踪易修改。</span><span class='green'>（除非用HTTPS）</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">73</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3．Cookie的大小限制在4KB左右。</span><span class='green'>对于复杂的存储需求来说是不够用的。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">74</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.3.3 Cookie在本研究中的作用</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">75</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>目前很多网站需要登录后才能访问站点中的内容，在登录之前，我们不具备访问的权限，也自然不能抓取内容。</span><span class='green'>所以可以利用Urllib2库的特性保存我们登录的Cookie，在爬虫运行后可以自动登录，也就可以进行抓抓取了。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">76</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>在本文实现的网络爬虫以“新浪微博”为目标网站，爬取其中的用户信息、微博内容等。</span><span class='green'>所以我们首先需要以用户身份进入网站才能继续爬取，由此合理利用Cookie的特性将帮助我们实现这样的需求。</span><span class='green'>相关细节将在下章继续介绍。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">77</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.4 Robot协议在爬虫设计中的影响</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">78</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/186.htm' target='right' class='orange' >Robots协议也称为爬虫协议、爬虫规则、机器人协议，是互联网行业中约定俗称的一种准入规范。</a><span class='green'>Robot协议的目的在于保护网站内容，包括用户信息、网站数据等。</span><span class='green'>“规则”中将搜索引擎抓取网站内容的范围做了约定，包括网站是否希望被搜索引擎抓取，哪些内容不允许被抓取，而网络爬虫可以据此自动抓取或者不抓取该网页内容。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">79</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.4.1 Robot协议详解</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">80</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/190.htm' target='right' class='red' >Robots协议是Web提供商和搜索引擎或爬虫交互的一种方式，Robots.txt是存放在站点服务器根目录下的一个纯文本文件。</a><a href='../sentence_detail/191.htm' target='right' class='orange' >该文件规定了搜索引擎爬虫只抓取指定的内容，或者是禁止搜索引擎爬虫抓取网站的部分或全部内容。</a><a href='../sentence_detail/192.htm' target='right' class='red' >当一个搜索引擎爬虫访问一个站点时，它会首先检查该站点根目录下是否存在robots.txt，如果存在，搜索引擎爬虫就会按照该文件中的内容来确定访问的范围；</a><span class='green'>如果该文件不存在，那么搜索引擎爬虫就沿着链接抓取。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">81</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.4.2 Robot.txt应用示例</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">82</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1.</span><span class='green'>User.agent:</span><span class='green'>用于描述访问该站点的客户端的名字标识。</span><span class='green'>被记录在Robot.txt中的User-agent记录将不被允许索引或爬取此站点。</span><span class='green'>通常浏览器的User-agent属性都是被运行的。</span><span class='green'>在Robots.txt文件中，“User-agent:</span><span class='green'>*这样的记录只能有一条。</span>
</p>
</div>


<div>
<span style="margin-left:25px"></span>
[
<a class="pagelink" href="paper_1.htm">首页</a>
<a class="pagelink" href="paper_1.htm">上一页</a>
<a class="pagelink" href="paper_3.htm">下一页</a>
<a class="pagelink" href="paper_6.htm">尾页</a>
页码：2/6页
]
</div>

<br>
<div style="margin-left:8px">

<div style="text-align:center;background-color:#CA122C;margin-top:30px;overflow:hidden;">
<a href="http://www.paperpass.com/publish/index?from=ppreport_banner" target="_blank" style="display:block;"><img height="180" src="http://file.paperpass.com/images/fabiao.jpg"></a>
</div>

</div>
</div>


<div class="zhengwencenter">
<p>
检测报告由<a href="http://www.paperpass.com/" target="_blank">PaperPass</a>文献相似度检测系统生成
</p>
<p>
Copyright © 2007-2016 PaperPass
</p>
</div>
<div style="margin-bottom:400px"></div>
</body>
</html>
