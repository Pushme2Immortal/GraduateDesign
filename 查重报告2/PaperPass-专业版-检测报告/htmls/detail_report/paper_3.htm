<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>PaperPass 最权威论文抄袭检测系统</title>
<style type="text/css">
<!--
user_icon {
color: #FFFFFF;
}
html
{
overflow-x:hidden;
overflow-y:auto;
}
body,td,th {
font-family: "微软雅黑";
font-size: 12px;
}
h1,h2,h3,h4,h5,h6 {
font-family: "宋体";
}
p{
margin-bottom:10px;
}
demo_padding {
line-height: 30px;
}
.zhengwen {
padding-right: 15px;
padding-left: 5px;
padding-bottom:100px;
font-size: 13px;
line-height: 20px;
color: #666666;
}
.zhengwencenter {
padding-right: 15px;
padding-left: 0px;
margin-bottom:10px;
font-size: 13px;
line-height: 20px;
color: #666666;
text-align:center
}
.neikuang {
background-color: #EBEBEB;
border: 1px solid #999999;
padding-right: 10px;
padding-left: 10px;
margin-top:10px;
margin-left:25px;
width:300px;
}
.shubu{
height: 20px;
width: 20px;
margin-left:25px;
background-color: #FFFFFF;
border: 1px solid #999999;
text-align: center;
vertical-align: middle;
display: block;
color: #666666;
}
a.red:link {color:#FF0000}
a.red:visited {color:#FF0000}
a.red:hover {color:#000000}
a.red:active {color:#000000}

a.orange:link {color:#FF6600}
a.orange:visited {color:#FF6600}
a.orange:hover {color:#000000}
a.orange:active {color:#000000}

a.dark:link {color:#666666}
a.dark:visited {color:#666666}
a.dark:hover {color:#000000}
a.dark:active {color:#000000}

a.pagelink:hover {color:#000000}
a.pagelink:active {color:#000000}

.green{color:#008000}
.gray{color:#666666}
.red{color:#FF0000}
.orange{color:#FF6600}
a{TEXT-DECORATION:none}

-->
</style>
</head>
<body>


<div class="zhengwen">
<div>
<span style="margin-left:25px"></span>
[
<a class="pagelink" href="paper_1.htm">首页</a>
<a class="pagelink" href="paper_2.htm">上一页</a>
<a class="pagelink" href="paper_4.htm">下一页</a>
<a class="pagelink" href="paper_6.htm">尾页</a>
页码：3/6页
]
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">83</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.</span><span class='green'>Disallow:</span><span class='green'>用于描述不希望被访问到的一个URL。</span><a href='../sentence_detail/205.htm' target='right' class='orange' >这个URL标识了某个站点资源的路径，任何被Disallow标记的URL将拒绝搜索引擎的索引或者来自爬虫的访问。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">84</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/206.htm' target='right' class='orange' >大部分商业搜索引擎或者爬虫要会遵守Robots协议并执行Web站点的要求。</a><span class='green'>所以在成熟的搜索模块或者爬虫中，需要设计一个处理站点Robot协议的模块，以增强自身的健壮性。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">85</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.4.3 Robot协议的缺点及影响</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">86</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>Robot协议并不是一个强制性的严格的法律协定，如果搜索引擎爬虫的设计者不遵循这个协议，其设计的代码也将能够自由爬取站点中的资源。</span><span class='green'>同时，站点管理员也有其他方式来限制网络爬虫在站点的运行。</span><span class='green'>所以，网站与爬虫的关系非常复杂，当我们在设计的过程中，必须要考虑这些限制，来增强爬虫的可行性。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">87</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>本文实现的爬虫将以”www.sina.com”即新浪微博为爬取目标，为了不受Robot协议的影响，我们将从User-agent入手，尝试解决方法。</span><span class='green'>具体方案将在下章继续陈述。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">88</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>第3章 Scrapy开源框架在爬虫开发中的应用</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">89</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>Scrapy是一个目的为了爬取网站内容，提取结构性数据而编写的开源爬虫应用框架。</span><span class='green'>可以运用在包括数据挖掘，信息处理或者存储历史数据等一系列的程序中。</span><span class='green'>本文使用Scrapy框架可以方便地自定义爬虫的爬取规则，同时还有很多稳定的开源库帮助我们进行前置后续处理。</span><span class='green'>实验证明，使用Scrapy开发的效果很好。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">90</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.1 Scrapy 分析与使用</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">91</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>Scrapy是利用Python语言编写的网络爬虫框架。</span><a href='../sentence_detail/221.htm' target='right' class='orange' >Python是一种具有高度集成性、拥有丰富开源库的计算机程序设计语言。</a><span class='green'>Scrapy最初的设计目的是页面抓取，或者说是网络抓取，当然也可以是用来获取各种API返回的数据。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">92</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>Scrapy作为爬虫框架，使得爬虫的设计和工作变得快速简单，同时具有高度的扩展性和鲁棒性。</span><span class='green'>所以Scrapy在爬虫设计中使用广泛，也符合本文所设计的爬虫应具有的特性，因此我们使用Scrapy来完成研究。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">93</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.1.1 Scrapy 简明介绍</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">94</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>下图3-1概括了Scrapy的整体架构，Scrapy主要包括了以下组件：</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">95</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1.</span><span class='green'>Scrapy Engine:</span><span class='green'>负责处理整个项目的数据流，触发事务。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">96</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.</span><span class='green'>Scheduler ：</span><span class='green'>接收引擎发送过来的请求，压入处理队列，并在引擎再次请求时返回。</span><span class='green'>可以类比为以URL为元素的优先队列，决定了爬虫下一个将要抓取的目标或者网页是什么，同时该部分还要负责URL去重。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">97</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图3-1 Scrapy框架的组成</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">98</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.</span><span class='green'>Downloader：</span><span class='green'>当爬虫爬取某个网页时，该部分将此网页内容下载至本机，并返回给爬虫。</span><span class='green'>该部分以异步方式工作，所以在多线程模型中将发挥很大的作用。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">99</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>4.</span><span class='green'>Spiders ：</span><span class='green'>整个爬虫项目中的核心部分，用于从特定的网页结构中提取目标信息，即所谓的尸体（Item）。</span><span class='green'>在设计中，用户可以规定爬虫提取网页中的URL并返回，使其自动运行爬取。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">100</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>5.</span><span class='green'>Pipeline ：</span><span class='green'>Pipeline是负责处理爬虫从网页中抽取的实体，比如结构化数据、转存数据库等。</span><span class='green'>当目标被爬虫获取并解析后，就会被发送到Pipeline，经过其中自定义的方法进行依次处理。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">101</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>6.</span><span class='green'>Downloader MIddlewares ：</span><span class='green'>位于Engine和downloader之间，负责处理这二者之间的request以及response</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">102</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>7.</span><span class='green'>spider MIddlewares 介于Engine和spider之间，处理爬虫的响应输出和请求输入。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">103</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>8.</span><span class='green'>scheduler middlewares：</span><span class='green'>位于Engine和scheduler之间，负责从Engine发送到网站或者服务器的请求和响应。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">104</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.1.2 Scrapy 爬虫的运行过程</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">105</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>Scrapy的运行流程基本如下 :</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">106</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1. 首先，Engine从Scheduler中调取一个URL作为爬取过程的初始目</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">107</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>标。</span><span class='green'>爬虫将从这个URL开始抓取。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">108</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.</span><span class='green'>Engine将URL封装为Request传送给Downloader，downloader将资源下载到本机，封装为Response</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">109</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.</span><span class='green'>Spider接收Response并调用回调函数。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">110</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>4. 如果从该REsponse中接收到实体，则交给pipeline做后续处理</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">111</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>5. 如果解析的结果为URL，则将URL发送给Scheduler等待被调用抓取。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">112</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>scrapy的安装不再赘述。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">113</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.1.3 Scrapy 的初步使用</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">114</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1. 创建项目</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">115</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>scrapy项目的创建或者使用方法非常便利，可以通过命令行的方式（如创建命令：</span><span class='green'>scrapy startproject testspider），也可以使用核心API通过编程的方式。</span><a href='../sentence_detail/271.htm' target='right' class='red' >为了获得更高的定制性和灵活性，我们主要使用后者的方式。</a><span class='green'>在这里我们使用了流行的Python语言集成编译环境Pycharm来创建我们的项目，将会得到如下的项目文件夹，如下图3-2所示：</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">116</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>大致介绍文件的作用：</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">117</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1）scrapy.cfg ：</span><span class='green'>该项目的配置文件</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">118</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2）内层Sina_Spider文件夹：</span><span class='green'>该项目的Python模块，其中包含了项目的主要代码。</span><span class='green'>将在下一章中详细介绍。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">119</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3）Begin.py ：</span><span class='green'>为该项目的编译入口，通过运行该文件，将启动爬虫</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">120</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图3-2 Scrapy项目概览</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">121</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>开始工作，即为上文所说核心API编程方式启动。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">122</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.运行项目</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">123</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>可以通过控制台使用命令行方式来运行，首先使用“cd”命令进入该项目所在路径，然后调用python解释器运行Begin.py文件，即输入命令</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">124</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>python Begin.py</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">125</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>或者编辑Pycharm的Compiler Configuration，然后点击“run”按钮进行解释运行。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">126</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图3-2 编辑Scrapy项目的编译设置</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">127</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.1.4 Scrapy 的其他特性</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">128</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>1.异步处理：</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">129</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>请求(request)是 被异步调度和处理的。</span><span class='green'>这意味着，Scrapy并不需要等待一个请求(request)完成及处理，在此同时，也发送其他请求或者做些其他事情。</span><span class='green'>这也意味着，当有些请求失败或者处理过程中出现错误时，其他的请求也能继续处理。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">130</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.多重控制：</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">131</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>在可以以非常快的速度进行爬取时(以容忍错误的方式同时发送多个request)， Scrapy也通过一些设置来允许您控制其爬取的方式。</span><span class='green'>例如，可以为两个request之间设置下载延迟，限制单域名(domain)等。</span><span class='green'>或单个IP的并发请求量，甚至可以使用自动限制插件来自动处理这些问题。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">132</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.2 数据的存取</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">133</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>使用Scrapy爬虫得到的数据是返回的结果，如何处理这些数据需要认真的考虑。</span><span class='green'>使用数据库而不是文件来存储，可以使用我们可以进行进一步的处理和分析。</span><span class='green'>所以在这里，我们要探讨如何使用数据库来存储爬虫返回结果。</span>
</p>
</div>


<div>
<span style="margin-left:25px"></span>
[
<a class="pagelink" href="paper_1.htm">首页</a>
<a class="pagelink" href="paper_2.htm">上一页</a>
<a class="pagelink" href="paper_4.htm">下一页</a>
<a class="pagelink" href="paper_6.htm">尾页</a>
页码：3/6页
]
</div>

<br>
<div style="margin-left:8px">

<div style="text-align:center;background-color:#CA122C;margin-top:30px;overflow:hidden;">
<a href="http://www.paperpass.com/publish/index?from=ppreport_banner" target="_blank" style="display:block;"><img height="180" src="http://file.paperpass.com/images/fabiao.jpg"></a>
</div>

</div>
</div>


<div class="zhengwencenter">
<p>
检测报告由<a href="http://www.paperpass.com/" target="_blank">PaperPass</a>文献相似度检测系统生成
</p>
<p>
Copyright © 2007-2016 PaperPass
</p>
</div>
<div style="margin-bottom:400px"></div>
</body>
</html>
